{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: leipzig-corpus/eng-eu_web_2015_10K-sentences.txt\n",
      "Extracted 4058 tokens\n",
      "[[['01.08.2011', False], ['Public', False], ['call', False], ['for', False], ['standard', False], ['projects', False], ['No.', False], ['02/2009', False], ['.', False]], [['â€¢', False], ['05.00', False], ['Energy', False], ['Rating', False], ['Introduce', False], ['energy', False], ['rating', False], ['models', False], ['for', False], ['selected', False], ['technologies', False], ['based', False], ['on', False], ['high', False], ['resolution', False], ['databases', False], ['in', False], ['the', False], ['Photovoltaic', False], ['Geographic', False], ['Information', False], ['System', False], ['(PVGIS),', False], ['also', False], ['in', False], ['collaboration', False], ['with', False], ['ENEA', True], ['06.00', False], ['Estimating', False], ['annual', False], ['farming', False], ['GHG', False], ['emissions', False], ['(including', False], ['Nitrous', False], ['Oxide', False], ['(N2O)', False], ['from', False], ['soils)', False], ['from', False], ['biofuels', False], ['crops', False], ['in', False], ['EU-NUTS2', False], ['regions', False], ['.', False]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "CORPUS_PATH = \"leipzig-corpus\"\n",
    "TRAIN_FILE = \"run-on-train.json\"\n",
    "TEST_FILE = \"run-on-test.json\"\n",
    "\n",
    "def iter_islast(iterable):\n",
    "    it = iter(iterable)\n",
    "    prev = it.__next__()\n",
    "    for item in it:\n",
    "        yield prev, False\n",
    "        prev = item\n",
    "    yield (prev[:-1], prev[-1]), True\n",
    "\n",
    "def extract_tokens_file(filename):\n",
    "    tokens = []\n",
    "    if filename.endswith(\"eng-eu_web_2015_10K-sentences.txt\"):\n",
    "        print(\"Processing: {}\".format(filename))\n",
    "        with open(filename, \"r\") as f:\n",
    "\n",
    "            text = f.read().split(\"\\n\")\n",
    "            res = []\n",
    "            run_on_mode = False\n",
    "            for line in text:\n",
    "                if line:\n",
    "                    line = line.split(\"\\t\")[1]\n",
    "                    for token, is_last in iter_islast(line.split(\" \")):\n",
    "                        if is_last:\n",
    "                            token1, token2 = token\n",
    "                            #around 70% that it is run on\n",
    "                            is_run_on = random.randint(1, 10) < 7\n",
    "                            if is_run_on:\n",
    "                                res.append([token1, True])\n",
    "                                run_on_mode = True\n",
    "                            else:\n",
    "                                #this is the end of sentence\n",
    "                                res.append([token1, False])\n",
    "                                res.append([token2, False])\n",
    "                                tokens.append(res)\n",
    "                                res = []\n",
    "                        else:\n",
    "                            if run_on_mode:\n",
    "                                if random.randint(0, 1): #this is 50% that run on is lower\n",
    "                                    res.append([token.lower(), False])\n",
    "                                    continue\n",
    "                                run_on_mode = False\n",
    "                            res.append([token, False])\n",
    "    return tokens\n",
    "\n",
    "with open(TRAIN_FILE, \"w\") as f:\n",
    "    tokens = [extract_tokens_file(\"{}/{}\".format(CORPUS_PATH, fl)) for fl in os.listdir(CORPUS_PATH)]\n",
    "    tokens = [item for sublist in tokens for item in sublist]\n",
    "    print(\"Extracted {} sentences\".format(len(tokens)))\n",
    "    print(tokens[:2])\n",
    "    res = json.dumps(tokens, indent=4)\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    label = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(f):\n",
    "    features, labels = [], []\n",
    "    with open(f, \"r\") as fl:\n",
    "        for sent in  json.loads(fl.read()):\n",
    "            for i in range(len(sent)):\n",
    "                f, label = word2features(sent, i) \n",
    "                features.append(f)\n",
    "                labels.append(label)\n",
    "    return features, labels\n",
    "train_features, train_labels = get_tokens(TRAIN_FILE)\n",
    "test_features, test_labels = get_tokens(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'public',\n",
       "  'BOS': True,\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': '01.08.2011',\n",
       "  'word[-2:]': '11',\n",
       "  'word[-3:]': '011'},\n",
       " {'+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'call',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': '01.08.2011',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'public',\n",
       "  'word[-2:]': 'ic',\n",
       "  'word[-3:]': 'lic'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test labels Counter({False: 4542, True: 155})\n",
      "train labels Counter({False: 199687, True: 5941})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"test labels {}\".format(Counter(test_labels)))\n",
    "print(\"train labels {}\".format(Counter(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "x_train = vec.fit_transform(train_features).toarray()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ls = LogisticRegression()\n",
    "ls.fit(x_train[:5000], train_labels[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vec.transform(test_features).toarray()\n",
    "y_pred = ls.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      1.00      0.98      4542\n",
      "       True       0.00      0.00      0.00       155\n",
      "\n",
      "avg / total       0.94      0.97      0.95      4697\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmarchenko/projects/prj-nlp/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import logging\n",
    "import spacy \n",
    "import spacy.symbols as ss\n",
    "from spacy import displacy\n",
    "import en_core_web_lg\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from kanren import run, eq, membero, var, conde, Relation, facts, fact, unifiable\n",
    "import wikipedia as wiki\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading previously generated train, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0).assign(doc = lambda df: df.sent.apply(nlp))\n",
    "test = pd.read_csv('test.csv', index_col=0).assign(doc = lambda df: df.sent.apply(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, match_fn):\n",
    "    predicted = X.apply(lambda x: match_fn(x))\n",
    "    predicted_year = predicted.apply(lambda p: p[REL_DATE] if REL_DATE in p else None)\n",
    "    predicted_title = predicted.apply(lambda p: p[BOOK_NAME] if BOOK_NAME in p else None)\n",
    "    return {'predicted_year': predicted_year, 'predicted_title': predicted_title}\n",
    "\n",
    "def evaluate(t):\n",
    "    ttp = np.sum(pd.notna(t.title) & pd.notna(t.predicted_title) & (t.title == t.predicted_title))\n",
    "    tfp = np.sum(pd.isna(t.title) & pd.notna(t.predicted_title))\n",
    "    tfn = np.sum(pd.notna(t.title) & pd.isna(t.predicted_title))\n",
    "    tprec = ttp / (ttp + tfp)\n",
    "    trecall = ttp / (ttp + tfn)\n",
    "    \n",
    "    ytp = np.sum(pd.notna(t.year) & pd.notna(t.predicted_year) & (t.year == t.predicted_year))\n",
    "    yfp = np.sum(pd.isna(t.year) & pd.notna(t.predicted_year))\n",
    "    yfn = np.sum(pd.notna(t.year) & pd.isna(t.predicted_year))\n",
    "    yprec = ytp / (ytp + yfp)\n",
    "    yrecall = ytp / (ytp + yfn)\n",
    "    return {'title': (tprec, trecall), 'year': (yprec, yrecall)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define rule-based extractor based on Kanren logic engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_NAME = '__BOOK_NAME__'\n",
    "REL_DATE = '__REL_DATE__'\n",
    "AUTHOR = '__AUTHOR__'\n",
    "REL_SYN = {'release', 'publish', 'accept', 'write', 'finish'}\n",
    "BOOK_SYN2 = {'book', 'novel', 'novella','story', 'piece', 'collection','tale', 'manuscript', 'sequel', 'article'}\n",
    "PREP_SYN = {'on', 'in', 'around'}\n",
    "WRITER_ATTRS_SYNS = {'novelist','essayist','writer', 'author', 'biographer',\n",
    "                     'columnist', 'critic', 'dramatist', 'editor',\n",
    "                     'journalist', 'poet'}\n",
    "\n",
    "DEPS = ['nsubjpass','dobj', 'prep', 'pobj', 'appos', 'acl', 'nsubj', 'attr']\n",
    "POSS = ['PROPN', 'NUM']\n",
    "ENTS = ['DATE', 'PERSON']\n",
    "COMS = ['LEMMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates db of relations between words and theirs attributes\n",
    "def gather_facts(doc):\n",
    "    R = {}\n",
    "    \n",
    "    for r in DEPS+POSS+ENTS+COMS:\n",
    "        R[r] = Relation(r)\n",
    "    \n",
    "    for tok in doc:\n",
    "        facts(R['LEMMA'], (tok.i, tok.lemma_))\n",
    "        if tok.pos_ in POSS:\n",
    "            fact(R[tok.pos_], (tok.i))\n",
    "        if tok.dep_ in DEPS:\n",
    "            facts(R[tok.dep_], (tok.head.i, tok.i))\n",
    "        if tok.ent_type_ in ENTS:\n",
    "            fact(R[tok.ent_type_], (tok.i))\n",
    "            \n",
    "    return R\n",
    "        \n",
    "# Checks that element by this id has lemma from the list\n",
    "def memberoi(R, idx, lst):\n",
    "    l = var('l'+str(idx))\n",
    "    return conde((R['LEMMA'](idx, l), membero(l, lst)))\n",
    "\n",
    "def action(R, idx):\n",
    "    return memberoi(R, idx, REL_SYN)\n",
    "\n",
    "def book(R, idx):\n",
    "    return memberoi(R, idx, BOOK_SYN2)\n",
    "\n",
    "def prep(R, idx):\n",
    "    return memberoi(R, idx, PREP_SYN)\n",
    "\n",
    "def action_on_object(R, action_i, object_i):\n",
    "    return conde((R['nsubjpass'](action_i, object_i),),\n",
    "                 (R['dobj'](action_i, object_i),))\n",
    "\n",
    "def date_ent(R, idx):\n",
    "    \n",
    "    return conde(\n",
    "        (R[\"DATE\"](idx), conde((R[\"PROPN\"](idx),),\n",
    "                               (R[\"NUM\"](idx),)))\n",
    "    )\n",
    "\n",
    "def be(R, idx):\n",
    "    return R[\"LEMMA\"](idx, 'be')\n",
    "\n",
    "def author_attrs(R, idx):\n",
    "    l = var('l' + str(idx))\n",
    "    return conde((R['LEMMA'](idx, l), memberoi(R, l, WRITER_ATTRS_SYNS)))\n",
    "def author_attrs(R, idx):\n",
    "    l = var('l' + str(idx))\n",
    "    #return R['LEMMA'](idx, l)\n",
    "    return memberoi(R, idx, WRITER_ATTRS_SYNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule handles following patterns\n",
    "    \n",
    "    book , <name> , written in <date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Book_Date_Rule1(R):\n",
    "    _action_i = var('_action_i')\n",
    "    _book_i = var('_book_i')\n",
    "    _prep_i = var('_prep_i')\n",
    "    return [\n",
    "        action(R, _action_i),\n",
    "        book(R, _book_i),\n",
    "        prep(R, _prep_i),\n",
    "        \n",
    "        action_on_object(R, _action_i, _book_i),\n",
    "        R[\"appos\"](_book_i, _book_name_i),\n",
    "        R[\"prep\"](_action_i, _prep_i),\n",
    "        R[\"pobj\"](_prep_i, _date_i)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule handles following patterns\n",
    "\n",
    "    <name> written in <date>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Book_Date_Rule2(R):\n",
    "    _action_i = var('_action_i')\n",
    "    _prep_i = var('_prep_i')\n",
    "    return [\n",
    "        action(R, _action_i),\n",
    "        prep(R, _prep_i),\n",
    "        action_on_object(R, _action_i, _book_name_i),\n",
    "        R['prep'](_action_i, _prep_i),\n",
    "        R['pobj'](_prep_i, _date_i)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_Date_Rules = [Book_Date_Rule1, Book_Date_Rule2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule handles following patterns\n",
    "\n",
    "     <name> was novelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Author_Rule1(R):\n",
    "    _be_i = var('_be_i')\n",
    "    _author_attrs_i = var('_author_attrs_i')\n",
    "    return [\n",
    "        be(R, _be_i),\n",
    "        author_attrs(R, _author_attrs_i),\n",
    "        R['nsubj'](_be_i, _author_name_i),\n",
    "        R['attr'](_be_i, _author_attrs_i)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rules(doc, vs, rules_fns): \n",
    "    R = gather_facts(doc)\n",
    "    for rule_fn in rules_fns:\n",
    "        result = run(1, vs, *rule_fn(R))\n",
    "        if result:\n",
    "            return result\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts book names given only on word from it\n",
    "* if appos:\n",
    "    * grab tokens between commas or quotes or etc\n",
    "* if not appos:\n",
    "    * tries to find leftmost token that is not `PROPN`,`PART`, etc\n",
    "    * tries to find rightmost token that is not `PROPN`, `PART`, etc\n",
    "    * all tokens between leftmost and rightmost is the desired book name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "propn_parts = set([ss.PROPN, ss.PART, ss.ADP, ss.DET, ss.CCONJ, ss.NOUN])\n",
    "\n",
    "def valid_named_part(tok):\n",
    "    return (tok.pos in propn_parts) or tok.text == '-'\n",
    "        \n",
    "def find_book_name(doc, tok):\n",
    "    if tok.dep == ss.appos:\n",
    "        left = None\n",
    "        right = None\n",
    "        for idx in range(tok.i, 0, -1):\n",
    "            if doc[idx].pos == ss.PUNCT and doc[idx].text != '-':\n",
    "                left = idx\n",
    "                break\n",
    "        for idx in range(tok.i, len(doc)):\n",
    "            if doc[idx].pos == ss.PUNCT and doc[idx].text != '-':\n",
    "                right = idx\n",
    "                break\n",
    "                \n",
    "        return doc[left+1:right].text\n",
    "    elif tok.pos == ss.PROPN:\n",
    "        left = tok.i\n",
    "        right = tok.i + 1\n",
    "        for idx in range(tok.i, -1, -1):\n",
    "            if doc[idx].pos == ss.DET or (valid_named_part(doc[idx]) and any([doc[j].pos == ss.PROPN for j in range(idx, max(idx-3,-1),-1)])):\n",
    "                left = idx\n",
    "            else:\n",
    "                break\n",
    "        for idx in range(tok.i, len(doc)):\n",
    "            if valid_named_part(doc[idx]) and any([doc[j].pos == ss.PROPN for j in range(idx, min(idx+3,len(doc)))]):\n",
    "                right = idx\n",
    "            else:\n",
    "                break\n",
    "        return doc[left:right+1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entity(doc, idx):\n",
    "    for ent in doc.ents:\n",
    "        if idx >= ent.start and idx < ent.end:\n",
    "            return ent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(rel_date):\n",
    "    if rel_date:\n",
    "        m = re.findall(r\"\\d\\d\\d\\d\", str(rel_date))\n",
    "        if m:\n",
    "            return int(m[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function tries to match book name and year of publishing in the spacy `Doc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_book_and_year(doc):    \n",
    "    global _book_name_i\n",
    "    global _date_i\n",
    "    global _author_name_i\n",
    "    _book_name_i = var('_book_name_i')\n",
    "    _date_i = var('_date_i')\n",
    "    _author_name_i = var('_author_name_i')\n",
    "    results =  run_rules(doc, (_book_name_i, _date_i), Book_Date_Rules)\n",
    "    \n",
    "    for res in results:\n",
    "        if res:\n",
    "            (book_name_idx, date_idx) = res\n",
    "            if book_name_idx and date_idx:\n",
    "                book_tok = doc[book_name_idx]\n",
    "                rel_tok = doc[date_idx]\n",
    "                cand1 = find_entity(doc, book_tok.i)\n",
    "                cand2 = find_book_name(doc, book_tok)\n",
    "                book_name = None\n",
    "                if cand1 and not cand2:\n",
    "                    book_name = cand1\n",
    "                elif not cand1 and cand2:\n",
    "                    book_name = cand2\n",
    "                elif not (cand1 or cand2):\n",
    "                    return {}\n",
    "                elif len(cand1) > len(cand2):\n",
    "                    book_name = cand1\n",
    "                else:\n",
    "                    book_name = cand2\n",
    "                \n",
    "                return {BOOK_NAME: book_name, \n",
    "                        REL_DATE: extract_year(find_entity(doc, rel_tok.i))}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function tries to match author from the text, but returns one that is given through `title` param.\n",
    "It's fixes the problem that the first sentence in wikipedia article has own(full) author's name, but we need his\n",
    "well known name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_author(author):\n",
    "    s1 = re.sub(r\"(\\w)\\. ?(\\w)\\. \", r\"\\1.\\2. \", author)\n",
    "    s2 = re.sub(r\"(\\w)\\. ?(\\w)\\. ? (\\w)\\. \", r\"\\1.\\2.\\3. \", s1)\n",
    "    return s2\n",
    "\n",
    "def match_author(doc, title):\n",
    "    global _author_name_i\n",
    "    _author_name_i = var('_author_name_i')\n",
    "    result = run_rules(doc, (_author_name_i,), [Author_Rule1])\n",
    "    for author_name_i, in result:\n",
    "        return {AUTHOR: _normalize_author(title)}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "November 18, 1865\n",
      "June 1997\n",
      "early 1951\n",
      "July 1998\n",
      "16 July 2005\n",
      "None\n",
      "1997\n",
      "1871\n",
      "Mississippi\n",
      "April 2013\n",
      "1865\n",
      "US\n",
      "{'title': (0.8181818181818182, 0.5), 'year': (0.8888888888888888, 0.42105263157894735)}\n"
     ]
    }
   ],
   "source": [
    "t1 = train.assign(**predict(train.doc, match_book_and_year))\n",
    "print(evaluate(t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that precision is pretty good, but recall is not so good. It's probably a good idea to get new rules. But after analyzing data, we saw thath train examples have errors or it's really hard to find borders for book names without quotes. Also there is a problem in the first sentence with extracint date: \"on the <Date> in the New Yourk weekly\" here weekly also date :( The best idea would be to define some patterns for date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>doc</th>\n",
       "      <th>predicted_year</th>\n",
       "      <th>predicted_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>His first success as a writer came when his humorous tall tale \"The Celebrated Jumping Frog of Calaveras County\" was published on November 18, 1865, in the New York weekly The Saturday Press, bringing him national attention.</td>\n",
       "      <td>The Celebrated Jumping Frog of Calaveras County</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>(His, first, success, as, a, writer, came, when, his, humorous, tall, tale, \", The, Celebrated, Jumping, Frog, of, Calaveras, County, \", was, published, on, November, 18, ,, 1865, ,, in, the, New, York, weekly, The, Saturday, Press, ,, bringing, him, national, attention, .)</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>The Celebrated Jumping Frog of Calaveras County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>The Incident in the Philippines, posthumously published in 1924, was in response to the Moro Crater Massacre, in which six hundred Moros were killed.</td>\n",
       "      <td>The Incident in the Philippines</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>(The, Incident, in, the, Philippines, ,, posthumously, published, in, 1924, ,, was, in, response, to, the, Moro, Crater, Massacre, ,, in, which, six, hundred, Moros, were, killed, .)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>In June 1997, Bloomsbury published Philosopher's Stone with an initial print run of 1,000 copies, 500 of which were distributed to libraries.</td>\n",
       "      <td>Philosopher's Stone</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>(In, June, 1997, ,, Bloomsbury, published, Philosopher, 's, Stone, with, an, initial, print, run, of, 1,000, copies, ,, 500, of, which, were, distributed, to, libraries, .)</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Philosopher's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>==\\n\\nIn 1995, Rowling finished her manuscript for Harry Potter and the Philosopher's Stone on an old manual typewriter.</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>(=, =, \\n\\n, In, 1995, ,, Rowling, finished, her, manuscript, for, Harry, Potter, and, the, Philosopher, 's, Stone, on, an, old, manual, typewriter, .)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>His experiences in the American West inspired Roughing It, written during 1870–71 and published in 1872.</td>\n",
       "      <td>Roughing It</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>(His, experiences, in, the, American, West, inspired, Roughing, It, ,, written, during, 1870–71, and, published, in, 1872, .)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                 sent  \\\n",
       "56   His first success as a writer came when his humorous tall tale \"The Celebrated Jumping Frog of Calaveras County\" was published on November 18, 1865, in the New York weekly The Saturday Press, bringing him national attention.   \n",
       "307                                                                             The Incident in the Philippines, posthumously published in 1924, was in response to the Moro Crater Massacre, in which six hundred Moros were killed.   \n",
       "910                                                                                     In June 1997, Bloomsbury published Philosopher's Stone with an initial print run of 1,000 copies, 500 of which were distributed to libraries.   \n",
       "903                                                                                                          ==\\n\\nIn 1995, Rowling finished her manuscript for Harry Potter and the Philosopher's Stone on an old manual typewriter.   \n",
       "52                                                                                                                           His experiences in the American West inspired Roughing It, written during 1870–71 and published in 1872.   \n",
       "\n",
       "                                               title    year        author  \\\n",
       "56   The Celebrated Jumping Frog of Calaveras County  1865.0    Mark Twain   \n",
       "307                  The Incident in the Philippines  1924.0    Mark Twain   \n",
       "910                              Philosopher's Stone  1997.0  J.K. Rowling   \n",
       "903         Harry Potter and the Philosopher's Stone  1995.0  J.K. Rowling   \n",
       "52                                       Roughing It  1872.0    Mark Twain   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                    doc  \\\n",
       "56   (His, first, success, as, a, writer, came, when, his, humorous, tall, tale, \", The, Celebrated, Jumping, Frog, of, Calaveras, County, \", was, published, on, November, 18, ,, 1865, ,, in, the, New, York, weekly, The, Saturday, Press, ,, bringing, him, national, attention, .)   \n",
       "307                                                                                              (The, Incident, in, the, Philippines, ,, posthumously, published, in, 1924, ,, was, in, response, to, the, Moro, Crater, Massacre, ,, in, which, six, hundred, Moros, were, killed, .)   \n",
       "910                                                                                                        (In, June, 1997, ,, Bloomsbury, published, Philosopher, 's, Stone, with, an, initial, print, run, of, 1,000, copies, ,, 500, of, which, were, distributed, to, libraries, .)   \n",
       "903                                                                                                                             (=, =, \\n\\n, In, 1995, ,, Rowling, finished, her, manuscript, for, Harry, Potter, and, the, Philosopher, 's, Stone, on, an, old, manual, typewriter, .)   \n",
       "52                                                                                                                                                        (His, experiences, in, the, American, West, inspired, Roughing, It, ,, written, during, 1870–71, and, published, in, 1872, .)   \n",
       "\n",
       "     predicted_year                                  predicted_title  \n",
       "56           1865.0  The Celebrated Jumping Frog of Calaveras County  \n",
       "307             NaN                                             None  \n",
       "910          1997.0                              Philosopher's Stone  \n",
       "903             NaN                                             None  \n",
       "52              NaN                                             None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[pd.notna(t1.predicted_year) | pd.notna(t1.title)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_SENTS = 3\n",
    "\n",
    "def match_all(wikipage):\n",
    "    collected = []\n",
    "    author = None\n",
    "    for i, sent in enumerate(sent_tokenize(wikipage.content)):\n",
    "        s = nlp(sent)\n",
    "        binds = match_book_and_year(s)\n",
    "        date = binds.get(REL_DATE, None)\n",
    "        year = extract_year(date)\n",
    "        if i < FIRST_SENTS:\n",
    "            sent = re.sub(r\"\\([^\\(\\)]+\\)\", \"\", sent)\n",
    "            s = nlp(sent)\n",
    "            author = match_author(s, wikipage.title).get(AUTHOR, author)\n",
    "        elif not author:\n",
    "            print(\"No author found, skipping\")\n",
    "            break\n",
    "\n",
    "        if not year:\n",
    "            continue\n",
    "        if binds:\n",
    "            # print(s)\n",
    "            # print(binds)\n",
    "            collected.append([author, year, binds.get(BOOK_NAME)])\n",
    "    return collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db():\n",
    "    db = pd.read_csv('books_all.csv', index_col=0)[['authors', 'original_title', 'original_publication_year']]\n",
    "    db = db.rename(columns={'original_publication_year': 'year'})\n",
    "    db = db.dropna()\n",
    "    db['year'] = db['year'].apply(int)\n",
    "    db['original_title'] = db['original_title'].str.lower()\n",
    "    return db\n",
    "db = load_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for evaluating page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_year(db, author, title):\n",
    "    mask = (db['authors'].str.contains(author)) & (db['original_title'] == title.lower())\n",
    "    res = db['year'][mask].values\n",
    "    if len(res) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return res[0]\n",
    "\n",
    "\n",
    "def check_fact(db, fact):\n",
    "    db_year = ground_truth_year(db, fact[0], fact[2])\n",
    "    test_year = fact[1]\n",
    "    return db_year == test_year\n",
    "\n",
    "\n",
    "def check_facts(db, facts):\n",
    "    return [check_fact(db, fact) for fact in facts]\n",
    "\n",
    "\n",
    "def calc_accuracy(db, facts):\n",
    "    results = check_facts(db, facts)\n",
    "    return np.sum(results) / len(results)\n",
    "\n",
    "\n",
    "def evaluate_page(db, page_name):\n",
    "    wp = wiki.page(page_name)\n",
    "    facts = match_all(wp)\n",
    "    return (calc_accuracy(db, facts), facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page accuracy: 0.3333333333333333\n",
      "Gathered facts: [['Walt Whitman', 1855, 'Leaves of Grass'], ['Walt Whitman', 1865, 'George'], ['Walt Whitman', 1868, 'Poems of Walt Whitman']]\n"
     ]
    }
   ],
   "source": [
    "(acc, _facts) = evaluate_page(db, 'Walt Whitman')\n",
    "print('Page accuracy:', acc)\n",
    "print('Gathered facts:', _facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is author in db?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author has 1 books\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Walt Whitman</td>\n",
       "      <td>leaves of grass</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           authors   original_title  year\n",
       "id                                       \n",
       "1679  Walt Whitman  leaves of grass  1855"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = _facts[0][0]\n",
    "author_mask = db['authors'].str.contains(author)\n",
    "authors_books = db[author_mask]\n",
    "print('Author has {} books'.format(len(authors_books)))\n",
    "authors_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we have author, what books we have in wikipedia, but don't have in db?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 2 books from wikipedia and not from db\n",
      "Sample:\n",
      "['george', 'poems of walt whitman']\n"
     ]
    }
   ],
   "source": [
    "books_not_in_db = {fact[2].lower() for fact in _facts} - set(authors_books.original_title.values)\n",
    "print(\"There is {} books from wikipedia and not from db\".format(len(books_not_in_db)))\n",
    "print(\"Sample:\")\n",
    "print(list(books_not_in_db)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* Goodreads-10k corpus is not good corpus for fact checking. It lacks too many books.\n",
    "* It's better to write more rules to decrease rate of false negatives\n",
    "* Use of `logpy` gives us good readability and ready engine, but it is too slow. It's better to look at other kanren engines or improve one that I done for the first version of this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

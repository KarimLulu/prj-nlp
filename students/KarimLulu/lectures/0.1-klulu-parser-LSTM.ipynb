{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, Dense, Flatten, Conv1D, concatenate, Activation, LSTM, Dropout, Reshape, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers, Model, Sequential\n",
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from conllu import parse, parse_tree\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import bz2\n",
    "import json\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport parser\n",
    "from parser import Parser, Parse\n",
    "\n",
    "%aimport helpers\n",
    "from helpers import read_embeddings, ROOT, clean_deprel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_filename = \"ubercorpus.lowercased.tokenized.300d.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / \"repos/UD_Ukrainian-IU\"\n",
    "\n",
    "with list(data_dir.glob(\"*train*\"))[0].open() as f:\n",
    "    data = f.read()\n",
    "trees = parse(data)\n",
    "\n",
    "with list(data_dir.glob(\"*test*\"))[0].open() as f:\n",
    "    test_data = f.read()\n",
    "test_trees = parse(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(trees, form=\"form\"):\n",
    "    word_index = {}\n",
    "    pos_index = {}\n",
    "    dep_index = {}\n",
    "    for tree in trees:\n",
    "        for word in tree:\n",
    "            deprel = word[\"deprel\"]\n",
    "            word_id = len(word_index)+1\n",
    "            pos_id = len(pos_index)+1\n",
    "            dep_id = len(dep_index)+1\n",
    "            word_t = word[form].lower()\n",
    "            word_pos = word[\"upostag\"]\n",
    "            word_index[word_t] = word_index.get(word_t, word_id)\n",
    "            pos_index[word_pos] = pos_index.get(word_pos, pos_id)\n",
    "            dep_index[deprel] = dep_index.get(deprel, dep_id)\n",
    "\n",
    "    word_index[ROOT[\"form\"]] = len(word_index)+1\n",
    "    pos_index[ROOT[\"upostag\"]] = len(pos_index)+1\n",
    "    return word_index, pos_index, dep_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trees, parser):\n",
    "    o_labels = []\n",
    "    o_features = []\n",
    "    for tree in trees:\n",
    "        labels, features, _ = parser.parse(tree)\n",
    "        o_labels.extend(labels)\n",
    "        o_features.extend(features)\n",
    "    return o_labels, o_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index, pos_index, dep_index = build_vocabulary(trees+test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_vec, ndim, _ = read_embeddings(filename=vec_filename, word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VEC = np.zeros(ndim, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, ndim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_matrix[i] = word_2_vec.get(word, DEFAULT_VEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_stack_context(depth, stack, data):\n",
    "        if depth >= 3:\n",
    "            return data[stack[-1][\"id\"]], data[stack[-2][\"id\"]], data[stack[-3][\"id\"]]\n",
    "        elif depth >= 2:\n",
    "            return data[stack[-1][\"id\"]], data[stack[-2][\"id\"]], 0\n",
    "        elif depth == 1:\n",
    "            return data[stack[-1][\"id\"]], 0, 0\n",
    "        else:\n",
    "            return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buffer_context(k, buffer, data):\n",
    "        if k >= 3:\n",
    "            return data[buffer[0][\"id\"]], data[buffer[1][\"id\"]], data[buffer[2][\"id\"]]\n",
    "        elif k >= 2:\n",
    "            return data[buffer[0][\"id\"]], data[buffer[1][\"id\"]], 0\n",
    "        elif k == 1:\n",
    "            return data[buffer[0][\"id\"]], 0, 0\n",
    "        else:\n",
    "            return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse_context(word, deps, data, left=True):\n",
    "    if not word or word == -1:\n",
    "        return 0, (0, 0), (0, 0)\n",
    "    deps = deps[word[\"id\"]]\n",
    "    num = len(deps)\n",
    "    if not num:\n",
    "        return num, (0, 0), (0, 0)\n",
    "    elif num==1:\n",
    "        return num, (data[deps[0][0]], deps[0][1]), (0, 0)\n",
    "    else:\n",
    "        temp = sorted(deps, key=lambda x: x[0], reverse=left)\n",
    "        return num, (data[deps[0][0]], deps[0][1]), (data[deps[1][0]], deps[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_builder(stack, queue, tree, parse=None, word_index=word_index, \n",
    "                    pos_index=pos_index, dep_index=dep_index, form=\"form\",\n",
    "                    log=0):\n",
    "    words = []\n",
    "    tags = []\n",
    "    deps = []\n",
    "    depth = len(stack)\n",
    "    q_len = len(queue)\n",
    "    if ROOT not in tree:\n",
    "        tree = [ROOT, *tree]\n",
    "    \n",
    "    s0, s1, s2 = get_stack_context(depth, stack, tree)\n",
    "    q0, q1, q2 = get_buffer_context(q_len, queue, tree)\n",
    "    \n",
    "    # Left two child of the top stack\n",
    "    Ns0l, s0l1, s0l2 = get_parse_context(s0, parse.lefts, tree, left=True)  \n",
    "    # Right two child of the top stack\n",
    "    Ns0r, s0r1, s0r2 = get_parse_context(s0, parse.rights, tree, left=False)\n",
    "    # Left two child of the second element on stack\n",
    "    Ns1l, s1l1, s1l2 = get_parse_context(s1, parse.lefts, tree, left=True)\n",
    "    # Left two child of the second element on stack\n",
    "    Ns1r, s1r1, s1r2 = get_parse_context(s1, parse.rights, tree, left=False)\n",
    "    \n",
    "    _, s0l1l1, _ = get_parse_context(s0l1[0], parse.lefts, tree, left=True)\n",
    "    _, s0r1r1, _ = get_parse_context(s0r1[0], parse.rights, tree, left=False)\n",
    "    _, s1l1l1, _ = get_parse_context(s1l1[0], parse.lefts, tree, left=True)\n",
    "    _, s1r1r1, _ = get_parse_context(s1r1[0], parse.rights, tree, left=False)\n",
    "    \n",
    "    if log:\n",
    "        if s0:\n",
    "            print(s0[\"form\"], \"id =\", s0[\"id\"], parse.lefts[s0[\"id\"]],  parse.rights[s0[\"id\"]])\n",
    "            print()\n",
    "            print(\"Top stack (rights): \", s0r1, s0r2)\n",
    "            print()\n",
    "            print(\"Right for right: \", s0r1r1)\n",
    "            print()\n",
    "            print(\"Top stack (lefts): \", s0l1, s0l2)\n",
    "            print()\n",
    "            print(\"Left for left: \", s0l1l1)\n",
    "            print()\n",
    "            print()\n",
    "        print(\"=\"*20)\n",
    "        if s1:\n",
    "            print(s1[\"form\"], \"id =\", s1[\"id\"], parse.lefts[s1[\"id\"]],  parse.rights[s1[\"id\"]])\n",
    "            print()\n",
    "            print(\"Second stack (rights): \", s1r1, s1r2)\n",
    "            print()\n",
    "            print(\"Right for right: \", s1r1r1)\n",
    "            print()\n",
    "            print(\"Second stack (lefts): \", s1l1, s1l2)\n",
    "            print()\n",
    "            print(\"Left for left: \", s1l1l1)\n",
    "            print()\n",
    "            print()\n",
    "        print(\"=\"*20)\n",
    "    deps = [dep_index.get(s0l1[-1], 0), dep_index.get(s0l2[-1], 0),\n",
    "            dep_index.get(s0r1[-1], 0), dep_index.get(s0r2[-1], 0),\n",
    "            dep_index.get(s1l1[-1], 0), dep_index.get(s1l2[-1], 0),\n",
    "            dep_index.get(s1r1[-1], 0), dep_index.get(s1r2[-1], 0),\n",
    "            dep_index.get(s0l1l1[-1], 0), dep_index.get(s0r1r1[-1], 0),\n",
    "            dep_index.get(s1l1l1[-1], 0), dep_index.get(s1r1r1[-1], 0)]\n",
    "    \n",
    "    for x in [s0, s1, s2, q0, q1, q2, \n",
    "              s0l1[0], s0l2[0], s0r1[0], s0r2[0], \n",
    "              s1l1[0], s1l2[0], s1r1[0], s1r2[0],\n",
    "              s0l1l1[0], s0r1r1[0], s1l1l1[0], s1r1r1[0]]:\n",
    "        if x:\n",
    "            word = x[form].lower() if x[\"id\"] else \"ROOT\"\n",
    "            word_idx = word_index.get(word)\n",
    "            pos_idx = pos_index.get(x[\"upostag\"])\n",
    "            words.append(word_idx)\n",
    "            tags.append(pos_idx)\n",
    "        else:\n",
    "            words.append(x)\n",
    "            tags.append(x)\n",
    "    \n",
    "    dist = s0[\"id\"] - q0[\"id\"] if q0 and s0 else 0\n",
    "    nums = [dist, Ns0l, Ns0r, Ns1r, Ns1l]\n",
    "    features = [*words, *tags, *deps, *nums]\n",
    "    return features, len(words), len(tags), len(deps), len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-453-08aaa3e079f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparser1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-450-1dd7f867693b>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tree, oracle, log, feature_extractor, labeled, update_label_index)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stack:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"form\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"form\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 5)"
     ]
    }
   ],
   "source": [
    "parser1 = Parser()\n",
    "tree = trees[10]\n",
    "l, f, pairs, *_ = parser1.parse(tree, feature_extractor=feature_builder)\n",
    "len(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n=5):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trees, parser, feature_extractor):\n",
    "    o_labels = []\n",
    "    o_features = []\n",
    "    k = 0\n",
    "    for tree in trees:\n",
    "        labels, features, _, n_w, n_t, n_d, n_num = parser.parse(tree, feature_extractor=feature_extractor)\n",
    "        feature_chunks = list(chunks(features))\n",
    "        label_chunks = list(chunks(labels))\n",
    "        o_labels.extend(label_chunks)\n",
    "        o_features.extend(feature_chunks)\n",
    "        if tree in test_trees:\n",
    "            k += len(feature_chunks)\n",
    "    return o_labels, o_features, n_w, n_t, n_d, n_num, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features, n_w, n_t, n_d, n_num, k = get_data(trees+test_trees, parser, feature_builder)\n",
    "n_unq = len(np.unique([el for x in labels for el in x]))\n",
    "label_index = parser.label_index.copy()\n",
    "#X = np.asarray(features)\n",
    "X = pad_sequences(sequences=features, maxlen=5, padding=\"post\")\n",
    "y = to_categorical(pad_sequences(labels, padding=\"post\", value=n_unq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39142, 5, 86)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(39142, 5, 53)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6426"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "X.shape\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X.shape[0]-k#154709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6426, 5, 86)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6426, 5, 53)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_layer = Embedding(len(word_index)+1,\n",
    "                            ndim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_shape=(5, n_w),\n",
    "                            trainable=0,\n",
    "                            #mask_zero=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding_layer = Embedding(len(pos_index)+1,\n",
    "                                100,\n",
    "                                input_shape=(5, n_t),\n",
    "                                trainable=1,\n",
    "                                #mask_zero=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_embedding_layer = Embedding(len(dep_index)+1,\n",
    "                                100,\n",
    "                                input_shape=(5, n_d),\n",
    "                                trainable=1,\n",
    "                                #mask_zero=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence_input = Input(shape=(5, n_w, ), dtype='int32')\n",
    "word_embedded_sequences = word_embedding_layer(word_sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sequence_input = Input(shape=(5, n_t, ), dtype='int32')\n",
    "pos_embedded_sequences = pos_embedding_layer(pos_sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_sequence_input = Input(shape=(5, n_d, ), dtype='int32')\n",
    "dep_embedded_sequences = dep_embedding_layer(dep_sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Input(shape=(5, n_num,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Lambda(lambda x: x, output_shape=lambda s:s)(word_embedded_sequences)\n",
    "p = Lambda(lambda x: x, output_shape=lambda s:s)(pos_embedded_sequences)\n",
    "d = Lambda(lambda x: x, output_shape=lambda s:s)(pos_embedded_sequences)\n",
    "\n",
    "word = Reshape((5, -1))(word_embedded_sequences)\n",
    "pos = Reshape((5, -1))(pos_embedded_sequences)\n",
    "dep = Reshape((5, -1))(dep_embedded_sequences)\n",
    "x = concatenate(inputs=[word, pos, dep, features], axis=-1)\n",
    "#x = concatenate(inputs=[word_embedded_sequences, pos_embedded_sequences, dep_embedded_sequences], axis=1)\n",
    "x = LSTM(256, return_sequences=True)(x)\n",
    "# x = Dense(200, activation=\"relu\",\n",
    "#           kernel_regularizer=regularizers.l2(1e-8))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = Dense(200, activation=\"relu\",\n",
    "#          kernel_regularizer=regularizers.l2(1e-8))(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "preds = Dense(n_unq+1, activation='softmax',\n",
    "             kernel_regularizer=regularizers.l2(1e-8))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[word_sequence_input, pos_sequence_input, dep_sequence_input, features], outputs=preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           (None, 5, 18)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 5, 18)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 5, 12)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 5, 18, 300)   7751400     input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 5, 18, 100)   1900        input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 5, 12, 100)   5200        input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_68 (Reshape)            (None, 5, 5400)      0           embedding_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_69 (Reshape)            (None, 5, 1800)      0           embedding_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 5, 1200)      0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           (None, 5, 5)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 5, 8405)      0           reshape_68[0][0]                 \n",
      "                                                                 reshape_69[0][0]                 \n",
      "                                                                 reshape_70[0][0]                 \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  (None, 5, 256)       8869888     concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 5, 256)       0           lstm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 5, 86)        22102       dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,650,490\n",
      "Trainable params: 8,899,090\n",
      "Non-trainable params: 7,751,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32716 samples, validate on 6426 samples\n",
      "Epoch 1/6\n",
      "32716/32716 [==============================] - 102s 3ms/step - loss: 0.6187 - acc: 0.8274 - val_loss: 0.3851 - val_acc: 0.8776\n",
      "Epoch 2/6\n",
      "32716/32716 [==============================] - 100s 3ms/step - loss: 0.2937 - acc: 0.9093 - val_loss: 0.3546 - val_acc: 0.8837\n",
      "Epoch 3/6\n",
      "32716/32716 [==============================] - 100s 3ms/step - loss: 0.2215 - acc: 0.9329 - val_loss: 0.3282 - val_acc: 0.8912\n",
      "Epoch 4/6\n",
      "32716/32716 [==============================] - 101s 3ms/step - loss: 0.1763 - acc: 0.9482 - val_loss: 0.3218 - val_acc: 0.8942\n",
      "Epoch 5/6\n",
      "32716/32716 [==============================] - 105s 3ms/step - loss: 0.1434 - acc: 0.9599 - val_loss: 0.3205 - val_acc: 0.8943\n",
      "Epoch 6/6\n",
      "32716/32716 [==============================] - 111s 3ms/step - loss: 0.1185 - acc: 0.9682 - val_loss: 0.3241 - val_acc: 0.8948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1984994e0>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train[:, :, :n_w], X_train[:, :, n_w:n_w+n_t], X_train[:, :, n_w+n_t:n_w+n_t+n_d], X_train[:, :, n_w+n_t+n_d:]], \n",
    "          y_train, \n",
    "    validation_data=([X_test[:, :, :n_w], X_test[:, :, n_w:n_w+n_t], X_test[:, :, n_w+n_t:n_w+n_t+n_d], X_test[:, :, n_w+n_t+n_d:]], y_test), \n",
    "          epochs=6, \n",
    "          batch_size=128, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6426, 5, 53)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(object):\n",
    "\n",
    "    def __init__(self, label_index={}):\n",
    "        self.label_index = label_index\n",
    "\n",
    "    @property\n",
    "    def idx_2_label(self):\n",
    "        return {v:k for k,v in self.label_index.items()}\n",
    "\n",
    "    def get_action(self, stack, q, parse):\n",
    "        if stack and not q:\n",
    "            return \"reduce\"\n",
    "        if stack[-1][\"head\"] == q[0][\"id\"] and (stack[-1][\"id\"] not in\n",
    "            [child for child, _, _ in parse.relations]):\n",
    "            return \"left\"\n",
    "        elif q[0][\"head\"] == stack[-1][\"id\"]:\n",
    "            return \"right\"\n",
    "        elif (stack[-1][\"head\"] in [parent for _, parent, _ in parse.relations]\n",
    "              and q[0][\"head\"] < stack[-1][\"id\"]\n",
    "             ):\n",
    "            return \"reduce\"\n",
    "        else:\n",
    "            return \"shift\"\n",
    "\n",
    "    def parse(self, tree, oracle=None, log=False, feature_extractor=feature_builder,\n",
    "              labeled=True, update_label_index=True):\n",
    "        q = tree.copy()\n",
    "        parse = Parse(len(q))\n",
    "        stack = [ROOT]\n",
    "        labels = []\n",
    "        features = []\n",
    "        X = None\n",
    "        while q or stack:\n",
    "            if log:\n",
    "                print(\"Stack:\", [el[\"form\"] for el in stack])\n",
    "                print(\"Q:\", [el[\"form\"] for el in q])\n",
    "            feature_set, n_w, n_t, n_d, n_num = feature_extractor(stack, q, tree, parse)\n",
    "            if X is None:\n",
    "                X = [[0]*len(feature_set) for _ in range(5)]\n",
    "\n",
    "            deprel = \"\"\n",
    "            if oracle is not None:\n",
    "                X.append(feature_set)\n",
    "                X1 = np.array([X])[:, -5:, :]\n",
    "                probas = oracle.predict([X1[:, :, :n_w], X1[:, :, n_w:n_w+n_t], X1[:, :, n_w+n_t:n_w+n_t+n_d], X1[:, :, n_w+n_t+n_d:]])[0][-1]\n",
    "                pred_action_id = np.argmax(probas[:-1])\n",
    "                action = self.idx_2_label[pred_action_id]\n",
    "                if \"left\" in action or \"right\" in action:\n",
    "                    action, deprel = action.split(\"_\")\n",
    "            else:\n",
    "                action = self.get_action(stack or None, q or None, parse)\n",
    "\n",
    "            if action == \"left\":\n",
    "                if not deprel:\n",
    "                    deprel = stack[-1][\"deprel\"]\n",
    "                parse.add_relation(stack[-1][\"id\"], q[0][\"id\"], deprel)\n",
    "                stack.pop()\n",
    "            elif action == \"right\":\n",
    "                if not deprel:\n",
    "                    deprel = q[0][\"deprel\"]\n",
    "                parse.add_relation(q[0][\"id\"], stack[-1][\"id\"], deprel)\n",
    "                stack.append(q.pop(0))\n",
    "            elif action == \"reduce\":\n",
    "                stack.pop()\n",
    "            elif action == \"shift\":\n",
    "                stack.append(q.pop(0))\n",
    "\n",
    "            if deprel and labeled:\n",
    "                action = f\"{action}_{deprel}\"\n",
    "\n",
    "            if update_label_index:\n",
    "                action_id = len(self.label_index)\n",
    "                self.label_index[action] = self.label_index.get(action, action_id)\n",
    "\n",
    "            labels.append(self.label_index[action])\n",
    "            features.append(feature_set)\n",
    "        return labels, features, parse.relations, n_w, n_t, n_d, n_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_2 = Parser(label_index=parser.label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_2.parse(trees[10], oracle=model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.15903115e-01, 1.87113134e-08, 1.50927997e-06, 3.02281046e-06,\n",
       "       7.84482552e-07, 3.61475941e-07, 8.37425205e-07, 3.68968205e-04,\n",
       "       4.82182920e-01, 1.38126430e-03, 3.83996758e-06, 2.36211145e-05,\n",
       "       2.68178815e-06, 3.98485270e-07, 1.17341574e-06, 4.13677026e-06,\n",
       "       3.79314633e-06, 3.01612681e-06, 1.23759651e-06, 7.68834752e-07,\n",
       "       9.86726627e-06, 6.76154059e-07, 6.94048907e-08, 1.35740020e-05,\n",
       "       7.06582966e-07, 2.26338443e-06, 9.13313033e-06, 2.78579932e-07,\n",
       "       1.00672980e-06, 2.40710261e-08, 1.53771507e-05, 8.47092110e-07,\n",
       "       1.30005856e-06, 6.68538860e-08, 1.55672709e-07, 1.18812932e-05,\n",
       "       8.71451107e-08, 2.04935120e-07, 1.04762385e-07, 3.27955746e-07,\n",
       "       1.68782378e-07, 2.49601135e-06, 1.49091903e-07, 1.28983871e-07,\n",
       "       9.06340392e-06, 2.90587877e-07, 9.40967482e-08, 1.88750604e-07,\n",
       "       5.96386371e-07, 6.91959201e-08, 1.34921572e-06, 8.64127401e-07,\n",
       "       3.00875485e-08, 1.85938200e-06, 5.13750820e-06, 1.76854167e-06,\n",
       "       6.50185541e-08, 1.42991794e-07, 1.22090484e-07, 6.99757976e-08,\n",
       "       1.66561745e-06, 1.95331360e-08, 5.88410174e-08, 4.89658127e-08,\n",
       "       1.32757623e-06, 1.00342724e-07, 5.54113228e-07, 4.32880142e-07,\n",
       "       1.90883767e-07, 7.80306073e-06, 2.54288489e-06, 5.42671437e-08,\n",
       "       1.74626814e-06, 4.60811265e-07, 3.95008072e-07, 2.01807921e-07,\n",
       "       1.53348196e-06, 6.84211665e-09, 3.68111976e-08, 1.40887579e-07,\n",
       "       1.57566244e-08, 1.07099069e-07, 5.58147981e-08, 1.37223219e-08,\n",
       "       1.94918623e-08, 3.36137305e-07], dtype=float32)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_test[:1, :, :n_w], X_test[:1, :, n_w:n_w+n_t], X_test[:1, :, n_w+n_t:n_w+n_t+n_d], X_test[:, :, n_w+n_t+n_d:]])[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154709 samples, validate on 30661 samples\n",
      "Epoch 1/6\n",
      "154709/154709 [==============================] - 42s 274us/step - loss: 0.5945 - acc: 0.8259 - val_loss: 0.4348 - val_acc: 0.8603\n",
      "Epoch 2/6\n",
      "154709/154709 [==============================] - 43s 275us/step - loss: 0.3691 - acc: 0.8838 - val_loss: 0.3952 - val_acc: 0.8686\n",
      "Epoch 3/6\n",
      "154709/154709 [==============================] - 41s 263us/step - loss: 0.3129 - acc: 0.9002 - val_loss: 0.3809 - val_acc: 0.8725\n",
      "Epoch 4/6\n",
      "154709/154709 [==============================] - 39s 253us/step - loss: 0.2761 - acc: 0.9125 - val_loss: 0.3745 - val_acc: 0.8743\n",
      "Epoch 5/6\n",
      "154709/154709 [==============================] - 39s 253us/step - loss: 0.2494 - acc: 0.9206 - val_loss: 0.3690 - val_acc: 0.8768\n",
      "Epoch 6/6\n",
      "154709/154709 [==============================] - 40s 258us/step - loss: 0.2290 - acc: 0.9272 - val_loss: 0.3655 - val_acc: 0.8772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd248ec3a20>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train[:, :n_w], X_train[:, n_w:n_w+n_t], X_train[:, n_w+n_t:n_w+n_t+n_d], X_train[:, n_w+n_t+n_d:]], \n",
    "          y_train, \n",
    "    validation_data=([X_test[:, :n_w], X_test[:, n_w:n_w+n_t], X_test[:, n_w+n_t:n_w+n_t+n_d], X_test[:, n_w+n_t+n_d:]], y_test), \n",
    "          epochs=6, \n",
    "          batch_size=128, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LUAS(parser, trees, oracle=None, feature_extractor=None):\n",
    "    total, tpL, tpU, failed = 0, 0, 0, 0\n",
    "    for tree in trees:\n",
    "        golden = [(node[\"id\"], node[\"head\"], node[\"deprel\"]) for node in tree]\n",
    "        try:\n",
    "            _, _, predicted, *_ = parser_2.parse(tree, oracle=oracle, update_label_index=False,\n",
    "                                               feature_extractor=feature_extractor)\n",
    "            total += len(golden)\n",
    "            tpL += len(set(golden).intersection(set(predicted)))\n",
    "            tpU += len(set([(c,h) for c,h,_ in golden]).intersection([(c,h) for c,h,_ in predicted]))\n",
    "        except:\n",
    "            failed += 1\n",
    "    return total, tpL, tpU, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: 9\n",
      "Total: 14769\n",
      "Correctly defined (unlabeled): 11227\n",
      "Correctly defined (labeled): 10703\n",
      "UAS: 0.76\n",
      "LAS: 0.725\n"
     ]
    }
   ],
   "source": [
    "total, tpL, tpU, failed = LUAS(parser, test_trees, model, feature_extractor=feature_builder)\n",
    "print(\"Failed:\", failed)\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined (unlabeled):\", tpU)\n",
    "print(\"Correctly defined (labeled):\", tpL)\n",
    "print(\"UAS:\", round(tpU / total, 3))\n",
    "print(\"LAS:\", round(tpL / total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

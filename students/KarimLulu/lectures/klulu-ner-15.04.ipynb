{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=None, print_=True, mode=\"weighted\"):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = metrics.roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = metrics.recall_score(y_test, pred, average=mode)\n",
    "    output[\"Precision\"] = metrics.precision_score(y_test, pred, average=mode)\n",
    "    output[\"F1\"] = metrics.f1_score(y_test, pred, average=mode)\n",
    "    output[\"accuracy\"] = metrics.accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + el for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    output[\"conf_matrix\"] = pd.DataFrame(metrics.confusion_matrix(y_test, pred, labels=labels), \n",
    "                                         columns=columns, index=index)\n",
    "    report = metrics.classification_report(y_true=y_test, y_pred=pred, labels=labels)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            if \"matrix\" in key:\n",
    "                print(value)\n",
    "            else:\n",
    "                print(f\"{key}: {value:0.3f}\")\n",
    "        print(report)\n",
    "    return output, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 73\n"
     ]
    }
   ],
   "source": [
    "PATH =\"/home/karimlulu/repos/ner-uk/\"\n",
    "\n",
    "# Read tokens and positions of tokens from a file\n",
    "\n",
    "def read_tokens(filename):\n",
    "    tokens = []\n",
    "    pos = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        text = f.read().split(\"\\n\")\n",
    "        for line in text:\n",
    "            if len(line) == 0:\n",
    "                pos += 1\n",
    "            else:\n",
    "                for token in line.split(\" \"):\n",
    "                    tokens.append((token, pos, pos + len(token)))\n",
    "                    pos += len(token) + 1\n",
    "    return tokens\n",
    "\n",
    "# Read annotations and positions of annotations from a file\n",
    "\n",
    "def read_annotations(filename):\n",
    "    anno = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            annotations = line.split()\n",
    "            anno.append((int(annotations[2]), int(annotations[3]), annotations[1]))\n",
    "    return anno\n",
    "\n",
    "def extract_labels(anno, tokens):\n",
    "    labels = []\n",
    "    ann_id = 0\n",
    "    for token in tokens:\n",
    "        if ann_id < len(anno):\n",
    "            beg, end, label = anno[ann_id]\n",
    "            if token[1] < beg:\n",
    "                labels.append(\"--\")\n",
    "            # if token[1] == beg or (token[1] > beg and token[1] < end)\n",
    "            else:\n",
    "                labels.append(label)\n",
    "                if token[2] == end:\n",
    "                    ann_id += 1\n",
    "        else:\n",
    "            labels.append(\"--\")    \n",
    "    return labels\n",
    "\n",
    "# tokens = read_tokens(PATH + \"data/A_alumni.krok.edu.ua_Prokopenko_Vidrodzhennia_velotreku(5).tok.txt\")\n",
    "# anno = read_annotations(PATH + \"data/A_alumni.krok.edu.ua_Prokopenko_Vidrodzhennia_velotreku(5).tok.ann\")\n",
    "# labels = extract_labels(anno, tokens)\n",
    "\n",
    "# for i, j in zip(tokens, labels):\n",
    "#     print(i[0], j)\n",
    "\n",
    "# Extract list of files for training and testing\n",
    "\n",
    "dev_test = {\"dev\": [], \"test\": []}\n",
    "category = \"\"\n",
    "with open(PATH + \"doc/dev-test-split.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line in [\"DEV\", \"TEST\"]:\n",
    "            category = line.lower()\n",
    "        elif len(line) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            dev_test[category].append(line)\n",
    "\n",
    "print(len(dev_test[\"dev\"]), len(dev_test[\"test\"]))\n",
    "\n",
    "# Get train and test data and labels\n",
    "\n",
    "train_tokens, test_tokens, train_labels, test_labels = [], [], [], []\n",
    "\n",
    "for filename in dev_test[\"dev\"]:\n",
    "    try:\n",
    "        tokens = read_tokens(PATH + \"data/\" + filename + \".txt\")\n",
    "        train_tokens += tokens\n",
    "        train_labels += extract_labels(read_annotations(PATH + \"data/\" + filename + \".ann\"), tokens)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for filename in dev_test[\"test\"]:\n",
    "    try:\n",
    "        tokens = read_tokens(PATH + \"data/\" + filename + \".txt\")\n",
    "        test_tokens += tokens\n",
    "        test_labels += extract_labels(read_annotations(PATH + \"data/\" + filename + \".ann\"), tokens)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_counter(counter):\n",
    "    return  [(key, value*100/sum(counter.values())) for key, value in counter.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('--', 90.2701838973454),\n",
       "  ('ОРГ', 0.6002542743801194),\n",
       "  ('ЛОК', 1.2922140629016459),\n",
       "  ('РІЗН', 1.4005933068869452),\n",
       "  ('ПЕРС', 6.436754458485886)],\n",
       " [('--', 88.25913820418766),\n",
       "  ('ЛОК', 2.1195210025262976),\n",
       "  ('ОРГ', 3.1229036724091177),\n",
       "  ('ПЕРС', 5.706292907811541),\n",
       "  ('РІЗН', 0.792144213065384)])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train = Counter(train_labels)\n",
    "c_test = Counter(test_labels)\n",
    "normalize_counter(c_train), normalize_counter(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('На', 0, 2),\n",
       " ('довірливих', 3, 13),\n",
       " ('кіровоградців', 14, 27),\n",
       " ('полюють', 28, 35),\n",
       " ('шахраї', 36, 42),\n",
       " ('та', 43, 45),\n",
       " ('фірми-посередники', 46, 63),\n",
       " (',', 64, 65),\n",
       " ('які', 66, 69),\n",
       " ('за', 70, 72),\n",
       " ('1000', 73, 77),\n",
       " ('грн', 78, 81),\n",
       " ('.', 82, 83),\n",
       " ('готові', 84, 90),\n",
       " ('«', 91, 92),\n",
       " ('виготовити', 93, 103),\n",
       " ('»', 104, 105),\n",
       " ('біометричний', 106, 118),\n",
       " ('паспорт', 119, 126),\n",
       " (',', 127, 128),\n",
       " ('який', 129, 133),\n",
       " ('коштує', 134, 140),\n",
       " ('518', 141, 144),\n",
       " ('грн', 145, 148),\n",
       " ('.', 149, 150),\n",
       " ('Із', 152, 154),\n",
       " ('запровадженням', 155, 169),\n",
       " ('біометричних', 170, 182),\n",
       " ('паспортів', 183, 192),\n",
       " ('активізувалися', 193, 207)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUOTES = ['»', '«', '\"', \"'\"]\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(record, l_context, r_context):\n",
    "    word = record[0]\n",
    "    p = morph.parse(word)\n",
    "    pos = p[0].tag.POS\n",
    "    normal_form = p[0].normal_form\n",
    "    l_words = [el[0] for el in l_context]\n",
    "    r_words = [el[0] for el in r_context]\n",
    "    features = {\n",
    "        'word.lower()': normal_form.lower() or word.lower(),\n",
    "        'wort.pos': pos or \"NONE\",\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isquote()': word in QUOTES\n",
    "    }\n",
    "    if l_context:\n",
    "        for k,w in enumerate(l_words):\n",
    "            prefix = f\"word-{k+1}\"\n",
    "            p = morph.parse(w)\n",
    "            pos = p[0].tag.POS\n",
    "            normal_form = p[0].normal_form\n",
    "            features.update({prefix+\".lower()\": normal_form or w.lower(),\n",
    "                             prefix+\".pos\": pos or \"NONE\",\n",
    "                             prefix+\".isupper()\": w.isupper(),\n",
    "                             prefix+\".istitle()\": w.istitle(),\n",
    "                             prefix+\".isdigit()\": w.isdigit(),\n",
    "                             prefix+\".isquote()\": w in QUOTES})\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "    if r_context:\n",
    "        for k,w in enumerate(r_words):\n",
    "            p = morph.parse(w)\n",
    "            pos = p[0].tag.POS\n",
    "            normal_form = p[0].normal_form\n",
    "            prefix = f\"word+{k+1}\"\n",
    "            features.update({prefix+\".lower()\": normal_form or w.lower(),\n",
    "                             prefix+\".pos\": pos or \"NONE\",\n",
    "                             prefix+\".isupper()\": w.isupper(),\n",
    "                             prefix+\".istitle()\": w.istitle(),\n",
    "                             prefix+\".isdigit()\": w.isdigit(),\n",
    "                             prefix+\".isquote()\": w in QUOTES})\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(data, window=2, exclude=[\".\"]):\n",
    "    output = []\n",
    "    for i,record in enumerate(data):\n",
    "        l_context = []\n",
    "        r_context = []\n",
    "        k = 1\n",
    "        l_end = False\n",
    "        r_end = False\n",
    "        while k <= window:\n",
    "            if i+k>len(data)-1 or data[i+k] in exclude:\n",
    "                r_end = True\n",
    "            if i-k<0 or data[i-k] in exclude:\n",
    "                l_end = True\n",
    "            if not r_end:\n",
    "                r_context.append(data[i+k])\n",
    "            if not l_end:\n",
    "                l_context.append(data[i-k])\n",
    "            k += 1\n",
    "        features = word2features(record, l_context, r_context)\n",
    "        output.append(features)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3\n",
    "train = build_features(train_tokens, window=window)\n",
    "test = build_features(test_tokens, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "train_v = v.fit_transform(train)\n",
    "test_v = v.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight=\"balanced\", C=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_v, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.896\n",
      "Precision: 0.871\n",
      "F1: 0.876\n",
      "accuracy: 0.896\n",
      "      pred_--  pred_ЛОК  pred_ОРГ  pred_ПЕРС  pred_РІЗН\n",
      "--      60792        72       162        507        304\n",
      "ЛОК       973       300        18        176         18\n",
      "ОРГ      1636       130       239         83        100\n",
      "ПЕРС     2448       212        40       1279         19\n",
      "РІЗН      291        43        38         46        137\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         --       0.92      0.98      0.95     61837\n",
      "        ЛОК       0.40      0.20      0.27      1485\n",
      "        ОРГ       0.48      0.11      0.18      2188\n",
      "       ПЕРС       0.61      0.32      0.42      3998\n",
      "       РІЗН       0.24      0.25      0.24       555\n",
      "\n",
      "avg / total       0.87      0.90      0.88     70063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(test_v)\n",
    "labels = clf.classes_\n",
    "#labels.remove(\"--\")\n",
    "output, report = calc_metrics(pred=y_pred, y_test=test_labels, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

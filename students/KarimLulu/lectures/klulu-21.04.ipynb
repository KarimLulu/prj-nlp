{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse, parse_tree\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=None, print_=True, mode=\"weighted\"):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = metrics.roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = metrics.recall_score(y_test, pred, average=mode)\n",
    "    output[\"Precision\"] = metrics.precision_score(y_test, pred, average=mode)\n",
    "    output[\"F1\"] = metrics.f1_score(y_test, pred, average=mode)\n",
    "    output[\"Accuracy\"] = metrics.accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + str(el) for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, pred, labels=labels), \n",
    "                               columns=columns, index=index)\n",
    "    report = metrics.classification_report(y_true=y_test, y_pred=pred, labels=labels)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            print(f\"{key}: {value:0.3f}\")\n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"\\nReport:\")\n",
    "        print(report)\n",
    "    return output, report, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', \"ROOT\"),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / \"repos/UD_Ukrainian-IU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with list(data_dir.glob(\"*train*\"))[0].open() as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', 1),\n",
       "             ('form', 'У'),\n",
       "             ('lemma', 'у'),\n",
       "             ('upostag', 'ADP'),\n",
       "             ('xpostag', 'Spsl'),\n",
       "             ('feats', OrderedDict([('Case', 'Loc')])),\n",
       "             ('head', 2),\n",
       "             ('deprel', 'case'),\n",
       "             ('deps', None),\n",
       "             ('misc', OrderedDict([('Id', '0003')]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = trees[0]\n",
    "tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <- домі\n",
      "домі <- була\n",
      "римського <- патриція\n",
      "патриція <- домі\n",
      "Руфіна <- патриція\n",
      "була <- root\n",
      "прегарна <- фреска\n",
      "фреска <- була\n",
      ", <- зображення\n",
      "зображення <- фреска\n",
      "Венери <- зображення\n",
      "та <- Адоніса\n",
      "Адоніса <- Венери\n",
      ". <- була\n"
     ]
    }
   ],
   "source": [
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <- {}\".format(node[\"form\"], tree[head-1][\"form\"] if head>0 else \"root\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse_context(word, deps, data):\n",
    "    if not word or word == -1:\n",
    "        return 0, \"\", \"\"\n",
    "    deps = deps[word[\"id\"]]\n",
    "    num = len(deps)\n",
    "    if not num:\n",
    "        return num, \"\", \"\"\n",
    "    elif num==1:\n",
    "        return num, data[deps[-1]-1], \"\"\n",
    "    else:\n",
    "        return num, data[deps[-1]-1], data[deps[-1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue, tree, parse):\n",
    "    features = {}\n",
    "    stack_depth = len(stack)\n",
    "    s0 = stack[-1] if stack_depth else -1\n",
    "    q0 = queue[0] if queue else -1\n",
    "    \n",
    "    # Features for stack\n",
    "    if stack:\n",
    "        features[\"s0-form\"] = s0[\"form\"]\n",
    "        features[\"s0-tag\"] = s0[\"upostag\"]\n",
    "        features[\"s0-lemma\"] = s0[\"lemma\"]\n",
    "        features[\"s0-word-tag\"] = s0[\"form\"] + s0[\"upostag\"]\n",
    "        if s0[\"feats\"]:\n",
    "            for k, v in s0[\"feats\"].items():\n",
    "                features[f\"s0-{k}\"] = v\n",
    "    if stack_depth > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "        features[\"s1-word-tag\"] = stack[-2][\"form\"] + stack[-2][\"upostag\"]\n",
    "    \n",
    "    # Features for queue\n",
    "    if queue:\n",
    "        features[\"q0-form\"] = q0[\"form\"]\n",
    "        features[\"q0-tag\"] = q0[\"upostag\"]\n",
    "        features[\"q0-lemma\"] = q0[\"lemma\"]\n",
    "        features[\"q0-word-tag\"] = q0[\"form\"] + q0[\"upostag\"]\n",
    "        if q0[\"feats\"]:\n",
    "            for k, v in q0[\"feats\"].items():\n",
    "                features[f\"q0-{k}\"] = v \n",
    "    if len(queue) > 1:\n",
    "        features[\"q1-form\"] = queue[1][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[1][\"upostag\"]\n",
    "        features[\"q1-word-tag\"] = queue[1][\"form\"] + queue[1][\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "        #features[\"q2-word-tag\"] = queue[2][\"form\"] + queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "        \n",
    "    if queue and stack:\n",
    "        Ds0q0 = q0[\"id\"] - s0[\"id\"]\n",
    "        features[\"distance\"] = Ds0q0\n",
    "        features[\"q0-dist\"] = q0[\"form\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0-dist\"] = s0[\"form\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0q0-dist\"] = s0[\"lemma\"] + q0[\"lemma\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0-tag-dist\"] = s0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"q0-tag-dist\"] = q0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0q0-tag-dist\"] = s0[\"upostag\"] + q0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        \n",
    "    # Left two child for top stack\n",
    "    Ns0l, s0l1, s0l2 = get_parse_context(s0, parse.lefts, tree) \n",
    "    if s0l1:\n",
    "        features[\"s0l1\"] = s0l1[\"form\"]\n",
    "        features[\"s0l1-tag\"] = s0l1[\"upostag\"]   \n",
    "    if s0l2:\n",
    "        features[\"s0l2\"] = s0l2[\"form\"]\n",
    "        features[\"s0l2-tag\"] = s0l2[\"upostag\"]\n",
    "    \n",
    "    # Right two child for top stack\n",
    "    Ns0r, s0r1, s0r2 = get_parse_context(s0, parse.rights, tree)\n",
    "    if s0r1:\n",
    "        features[\"s0r1\"] = s0r1[\"form\"]\n",
    "        features[\"s0r1-tag\"] = s0r1[\"upostag\"] \n",
    "    if s0r2:\n",
    "        features[\"s0r2\"] = s0r2[\"form\"]\n",
    "        features[\"s0r2-tag\"] = s0r2[\"upostag\"]\n",
    "    \n",
    "    # Left two child for top queue\n",
    "    Nq0l, q0l1, q0l2 = get_parse_context(q0, parse.lefts, tree)\n",
    "    if q0l1:\n",
    "        features[\"q0l1\"] = q0l1[\"form\"]\n",
    "        features[\"q0l1-tag\"] = q0l1[\"upostag\"]  \n",
    "    if q0l2:\n",
    "        features[\"q0l2\"] = q0l2[\"form\"]\n",
    "        features[\"q0l2-tag\"] = q0l2[\"upostag\"]\n",
    "    \n",
    "    # Right two child for top stack\n",
    "    Nq0r, q0r1, q0r2 = get_parse_context(q0, parse.rights, tree)\n",
    "    if q0r1:\n",
    "        features[\"q0r1\"] = q0r1[\"form\"]\n",
    "        features[\"q0r1-tag\"] = q0r1[\"upostag\"]    \n",
    "    if q0r2:\n",
    "        features[\"q0r2\"] = q0r2[\"form\"]\n",
    "        features[\"q0r2-tag\"] = q0r2[\"upostag\"]\n",
    "    \n",
    "    if stack:\n",
    "        features[\"s0l-N\"] = s0[\"form\"] + f\"-{Ns0l}\"\n",
    "        features[\"s0r-N\"] = s0[\"form\"] + f\"-{Ns0r}\"\n",
    "        features[\"s0l-tag-N\"] = s0[\"upostag\"] + f\"-{Ns0l}\"\n",
    "        features[\"s0r-tag-N\"] = s0[\"upostag\"] + f\"-{Ns0r}\"\n",
    "    if queue:\n",
    "        features[\"q0l-N\"] = q0[\"form\"] + f\"-{Nq0l}\"\n",
    "        features[\"q0r-N\"] = q0[\"form\"] + f\"-{Nq0r}\"\n",
    "        features[\"q0l-tag-N\"] = q0[\"upostag\"] + f\"-{Nq0l}\"\n",
    "        features[\"q0r-tag-N\"] = q0[\"upostag\"] + f\"-{Nq0r}\"\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parse(object):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.relations = []\n",
    "        self.lefts = []\n",
    "        self.rights = []\n",
    "        # we need n+1 coz examples in the training data are indexed from 1\n",
    "        for k in range(n+1):\n",
    "            self.lefts.append([])\n",
    "            self.rights.append([])\n",
    "    \n",
    "    def add_relation(self, child, head):\n",
    "        self.relations.append((child, head))\n",
    "        if child < head:\n",
    "            self.lefts[head].append(child)\n",
    "        else:\n",
    "            self.rights[head].append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, stack, q, parse):\n",
    "        if stack and not q:\n",
    "            return \"reduce\"\n",
    "        if stack[-1][\"head\"] == q[0][\"id\"]:\n",
    "            return \"left\"\n",
    "        elif q[0][\"head\"] == stack[-1][\"id\"]:\n",
    "            return \"right\"\n",
    "        elif (stack[-1][\"head\"] in [parent for _, parent in parse.relations] \n",
    "              and q[0][\"head\"] < stack[-1][\"id\"]):\n",
    "            return \"reduce\"\n",
    "        else:\n",
    "            return \"shift\" \n",
    "        \n",
    "    def parse(self, tree, oracle=None, vectorizer=None):\n",
    "        q = tree.copy()\n",
    "        parse = Parse(len(q))\n",
    "        stack = [ROOT]\n",
    "        labels = []\n",
    "        features = []\n",
    "        while q or stack:\n",
    "            feature_set = extract_features(stack, q, tree, parse)\n",
    "            \n",
    "            if oracle is not None:\n",
    "                v_features = vectorizer.transform(feature_set)\n",
    "                action = oracle.predict(v_features)[0]\n",
    "            else:\n",
    "                action = self.get_action(stack or None, q or None, parse)\n",
    "            \n",
    "            if action == \"left\":\n",
    "                parse.add_relation(stack[-1][\"id\"], q[0][\"id\"])\n",
    "                stack.pop()\n",
    "            elif action == \"right\":\n",
    "                parse.add_relation(q[0][\"id\"], stack[-1][\"id\"])\n",
    "                stack.append(q.pop(0))\n",
    "            elif action == \"reduce\":\n",
    "                stack.pop()\n",
    "            elif action == \"shift\":\n",
    "                stack.append(q.pop(0))              \n",
    "            labels.append(action)\n",
    "            features.append(feature_set)\n",
    "        return labels, features, parse.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "labels, features, _ = parser.parse(tree)\n",
    "print(len(labels), len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trees, parser):\n",
    "    o_labels = []\n",
    "    o_features = []\n",
    "    for tree in trees:\n",
    "        labels, features, _ = parser.parse(tree)\n",
    "        o_labels.extend(labels)\n",
    "        o_features.extend(features)\n",
    "    return o_labels, o_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare train / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with list(data_dir.glob(\"*test*\"))[0].open() as f:\n",
    "    test_data = f.read()\n",
    "test_trees = parse(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 154709\n"
     ]
    }
   ],
   "source": [
    "y_train, features_train = get_data(trees, parser)\n",
    "print(len(features_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30661 30661\n"
     ]
    }
   ],
   "source": [
    "y_test, features_test = get_data(test_trees, parser)\n",
    "print(len(features_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=True)\n",
    "v_train = vectorizer.fit_transform(features_train)\n",
    "v_test = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=25)\n",
    "clf.fit(v_train, y_train)\n",
    "y_pred = clf.predict(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.894\n",
      "Precision: 0.894\n",
      "F1: 0.894\n",
      "Accuracy: 0.894\n",
      "\n",
      "Confusion matrix:\n",
      "        pred_left  pred_reduce  pred_right  pred_shift\n",
      "left         6983          139          54         190\n",
      "reduce        377         6954         838         187\n",
      "right          59          614        6312         232\n",
      "shift         220          132         211        7159\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.91      0.95      0.93      7366\n",
      "     reduce       0.89      0.83      0.86      8356\n",
      "      right       0.85      0.87      0.86      7217\n",
      "      shift       0.92      0.93      0.92      7722\n",
      "\n",
      "avg / total       0.89      0.89      0.89     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output, report, conf_matrix = calc_metrics(y_test, y_pred, labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add UAS calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UAS(trees, oracle=None, vectorizer=None):\n",
    "    total, tp, failed = 0, 0, 0\n",
    "    for tree in trees:\n",
    "        try:\n",
    "            golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "            _, _, predicted = parser.parse(tree, oracle=oracle, vectorizer=vectorizer)\n",
    "            total += len(golden)\n",
    "            tp += len(set(golden).intersection(set(predicted))) \n",
    "        except:\n",
    "            failed += 1\n",
    "    return total, tp, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: 10\n",
      "Total: 14602\n",
      "Correctly defined: 11277\n",
      "UAS: 0.772\n"
     ]
    }
   ],
   "source": [
    "total, tp, failed = UAS(test_trees, clf, vectorizer)\n",
    "print(\"Failed:\", failed)\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp / total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

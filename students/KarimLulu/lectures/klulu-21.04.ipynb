{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse, parse_tree\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=None, print_=True, mode=\"weighted\"):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = metrics.roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = metrics.recall_score(y_test, pred, average=mode)\n",
    "    output[\"Precision\"] = metrics.precision_score(y_test, pred, average=mode)\n",
    "    output[\"F1\"] = metrics.f1_score(y_test, pred, average=mode)\n",
    "    output[\"Accuracy\"] = metrics.accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + str(el) for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, pred, labels=labels), \n",
    "                               columns=columns, index=index)\n",
    "    report = metrics.classification_report(y_true=y_test, y_pred=pred, labels=labels)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            print(f\"{key}: {value:0.3f}\")\n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"\\nReport:\")\n",
    "        print(report)\n",
    "    return output, report, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', \"ROOT\"),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / \"repos/UD_Ukrainian-IU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with list(data_dir.glob(\"*train*\"))[0].open() as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', 1),\n",
       "             ('form', 'У'),\n",
       "             ('lemma', 'у'),\n",
       "             ('upostag', 'ADP'),\n",
       "             ('xpostag', 'Spsl'),\n",
       "             ('feats', OrderedDict([('Case', 'Loc')])),\n",
       "             ('head', 2),\n",
       "             ('deprel', 'case'),\n",
       "             ('deps', None),\n",
       "             ('misc', OrderedDict([('Id', '0003')]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = trees[0]\n",
    "tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <- домі\n",
      "домі <- була\n",
      "римського <- патриція\n",
      "патриція <- домі\n",
      "Руфіна <- патриція\n",
      "була <- root\n",
      "прегарна <- фреска\n",
      "фреска <- була\n",
      ", <- зображення\n",
      "зображення <- фреска\n",
      "Венери <- зображення\n",
      "та <- Адоніса\n",
      "Адоніса <- Венери\n",
      ". <- була\n"
     ]
    }
   ],
   "source": [
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <- {}\".format(node[\"form\"], tree[head-1][\"form\"] if head>0 else \"root\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse_context(word, deps, data):\n",
    "    if not word or word == -1:\n",
    "        return 0, \"\", \"\"\n",
    "    deps = deps[word[\"id\"]]\n",
    "    num = len(deps)\n",
    "    if not num:\n",
    "        return num, \"\", \"\"\n",
    "    elif num==1:\n",
    "        return num, data[deps[-1]-1], \"\"\n",
    "    else:\n",
    "        return num, data[deps[-1]-1], data[deps[-1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue, tree, parse):\n",
    "    features = {}\n",
    "    stack_depth = len(stack)\n",
    "    s0 = stack[-1] if stack_depth else -1\n",
    "    q0 = queue[0] if queue else -1\n",
    "    \n",
    "    # Features for stack\n",
    "    if stack:\n",
    "        features[\"s0-form\"] = s0[\"form\"]\n",
    "        features[\"s0-tag\"] = s0[\"upostag\"]\n",
    "        features[\"s0-lemma\"] = s0[\"lemma\"]\n",
    "        if s0[\"feats\"]:\n",
    "            for k, v in s0[\"feats\"].items():\n",
    "                features[f\"s0-{k}\"] = v\n",
    "    if stack_depth > 1:\n",
    "        features[\"s1-pos\"] = stack[-2][\"upostag\"]\n",
    "    \n",
    "    # Features for queue\n",
    "    if queue:\n",
    "        features[\"q0-form\"] = q0[\"form\"]\n",
    "        features[\"q0-tag\"] = q0[\"upostag\"]\n",
    "        features[\"q0-lemma\"] = q0[\"lemma\"]\n",
    "        if q0[\"feats\"]:\n",
    "            for k, v in q0[\"feats\"].items():\n",
    "                features[f\"q0-{k}\"] = v \n",
    "    if len(queue) > 1:\n",
    "        features[\"q1-form\"] = queue[1][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[1][\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "        \n",
    "    if queue and stack:\n",
    "        Ds0q0 = q0[\"id\"] - s0[\"id\"]\n",
    "        features[\"distance\"] = Ds0q0\n",
    "        features[\"q0-dist\"] = q0[\"form\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0-dist\"] = s0[\"form\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0q0-dist\"] = s0[\"lemma\"] + q0[\"lemma\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0-tag-dist\"] = s0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"q0-tag-dist\"] = q0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        features[\"s0q0-tag-dist\"] = s0[\"upostag\"] + q0[\"upostag\"] + \"-{}\".format(Ds0q0)\n",
    "        \n",
    "    # Left two child for top stack\n",
    "    Ns0l, s0l1, s0l2 = get_parse_context(s0, parse.lefts, tree) \n",
    "    if s0l1:\n",
    "        features[\"s0l1\"] = s0l1[\"form\"]\n",
    "    \n",
    "    if s0l2:\n",
    "        features[\"s0l2\"] = s0l2[\"form\"]\n",
    "    \n",
    "    # Right two child for top stack\n",
    "    Ns0r, s0r1, s0r2 = get_parse_context(s0, parse.rights, tree)\n",
    "    if s0r1:\n",
    "        features[\"s0r1\"] = s0r1[\"form\"]\n",
    "    \n",
    "    if s0r2:\n",
    "        features[\"s0r2\"] = s0r2[\"form\"]\n",
    "    \n",
    "    # Left two child for top queue\n",
    "    Nq0l, q0l1, q0l2 = get_parse_context(q0, parse.lefts, tree)\n",
    "    if q0l1:\n",
    "        features[\"q0l1\"] = q0l1[\"form\"]\n",
    "    \n",
    "    if q0l2:\n",
    "        features[\"q0l2\"] = q0l2[\"form\"]\n",
    "    \n",
    "    # Right two child for top stack\n",
    "    Nq0r, q0r1, q0r2 = get_parse_context(q0, parse.rights, tree)\n",
    "    if q0r1:\n",
    "        features[\"q0r1\"] = q0r1[\"form\"]\n",
    "    \n",
    "    if q0r2:\n",
    "        features[\"q0r2\"] = q0r2[\"form\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parse(object):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.relations = []\n",
    "        self.lefts = []\n",
    "        self.rights = []\n",
    "        # we need n+1 coz examples in the training data are indexed from 1\n",
    "        for k in range(n+1):\n",
    "            self.lefts.append([])\n",
    "            self.rights.append([])\n",
    "    \n",
    "    def add_relation(self, child, head):\n",
    "        self.relations.append((child, head))\n",
    "        if child < head:\n",
    "            self.lefts[head].append(child)\n",
    "        else:\n",
    "            self.rights[head].append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, stack, q, parse):\n",
    "        if stack and not q:\n",
    "            return \"reduce\"\n",
    "        if stack[-1][\"head\"] == q[0][\"id\"]:\n",
    "            return \"left\"\n",
    "        elif q[0][\"head\"] == stack[-1][\"id\"]:\n",
    "            return \"right\"\n",
    "        elif (stack[-1][\"head\"] in [parent for _, parent in parse.relations] \n",
    "              and q[0][\"head\"] < stack[-1][\"id\"]):\n",
    "            return \"reduce\"\n",
    "        else:\n",
    "            return \"shift\" \n",
    "        \n",
    "    def parse(self, tree, oracle=None, vectorizer=None):\n",
    "        q = tree.copy()\n",
    "        parse = Parse(len(q))\n",
    "        stack = [ROOT]\n",
    "        labels = []\n",
    "        features = []\n",
    "        while q or stack:\n",
    "            feature_set = extract_features(stack, q, tree, parse)\n",
    "            \n",
    "            if oracle is not None:\n",
    "                v_features = vectorizer.transform(feature_set)\n",
    "                action = oracle.predict(v_features)[0]\n",
    "            else:\n",
    "                action = self.get_action(stack or None, q or None, parse)\n",
    "            \n",
    "            if action == \"left\":\n",
    "                parse.add_relation(stack[-1][\"id\"], q[0][\"id\"])\n",
    "                stack.pop()\n",
    "            elif action == \"right\":\n",
    "                parse.add_relation(q[0][\"id\"], stack[-1][\"id\"])\n",
    "                stack.append(q.pop(0))\n",
    "            elif action == \"reduce\":\n",
    "                stack.pop()\n",
    "            elif action == \"shift\":\n",
    "                stack.append(q.pop(0))              \n",
    "            labels.append(action)\n",
    "            features.append(feature_set)\n",
    "        return labels, features, parse.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "labels, features, _ = parser.parse(tree)\n",
    "print(len(labels), len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trees, parser):\n",
    "    o_labels = []\n",
    "    o_features = []\n",
    "    for tree in trees:\n",
    "        labels, features, _ = parser.parse(tree)\n",
    "        o_labels.extend(labels)\n",
    "        o_features.extend(features)\n",
    "    return o_labels, o_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare train / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with list(data_dir.glob(\"*test*\"))[0].open() as f:\n",
    "    test_data = f.read()\n",
    "test_trees = parse(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 154709\n"
     ]
    }
   ],
   "source": [
    "y_train, features_train = get_data(trees, parser)\n",
    "print(len(features_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30661 30661\n"
     ]
    }
   ],
   "source": [
    "y_test, features_test = get_data(test_trees, parser)\n",
    "print(len(features_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=True)\n",
    "v_train = vectorizer.fit_transform(features_train)\n",
    "v_test = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=25, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=25)\n",
    "clf.fit(v_train, y_train)\n",
    "y_pred = clf.predict(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.889\n",
      "Precision: 0.889\n",
      "F1: 0.889\n",
      "Accuracy: 0.889\n",
      "\n",
      "Confusion matrix:\n",
      "        pred_left  pred_reduce  pred_right  pred_shift\n",
      "left         6924          151          95         196\n",
      "reduce        397         6946         825         188\n",
      "right          78          642        6269         228\n",
      "shift         238          128         224        7132\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.91      0.94      0.92      7366\n",
      "     reduce       0.88      0.83      0.86      8356\n",
      "      right       0.85      0.87      0.86      7217\n",
      "      shift       0.92      0.92      0.92      7722\n",
      "\n",
      "avg / total       0.89      0.89      0.89     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output, report, conf_matrix = calc_metrics(y_test, y_pred, labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add UAS calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UAS(trees, oracle=None, vectorizer=None):\n",
    "    total, tp = 0, 0\n",
    "    for tree in trees:\n",
    "        golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "        _, _, predicted = parser.parse(tree, oracle=oracle, vectorizer=vectorizer)\n",
    "        total += len(golden)\n",
    "        tp += len(set(golden).intersection(set(predicted))) \n",
    "    return total, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-c5e31ec634c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correctly defined:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UAS:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-e2e3dcfad18c>\u001b[0m in \u001b[0;36mUAS\u001b[0;34m(trees, oracle, vectorizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgolden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"head\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgolden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgolden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-21c1aaca232f>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tree, oracle, vectorizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moracle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mv_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karimlulu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/dict_vectorizer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karimlulu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/dict_vectorizer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         result_matrix = sp.csr_matrix((values, indices, indptr),\n\u001b[0;32m--> 190\u001b[0;31m                                       shape=shape, dtype=dtype)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Sort everything if asked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karimlulu/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karimlulu/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mcheck_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    146\u001b[0m                     % self.indices.dtype.name)\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0midx_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karimlulu/anaconda3/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \"\"\"\n\u001b[1;32m    121\u001b[0m     \u001b[0mBased\u001b[0m \u001b[0mon\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetermine\u001b[0m \u001b[0ma\u001b[0m \u001b[0msuitable\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total, tp = UAS(test_trees, clf, vectorizer)\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp / total, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

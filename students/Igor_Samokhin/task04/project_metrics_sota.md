## Курсовий проект: метрики, бейзлайн, state of the art

Мій курсовий проект присвячено відповідям на фактологічні запитання, на які можна відповісти з використанням української вікіпедії. Питально-відповідальні системи - активна сфера досліджень, у якій є дещо різні напрямки: інколи йдеться про reading comprehenstion (наскільки програма може відповісти на питання по тексту, прочитавши цей текст), інколи - про знаходження релевантного речення зі статті вікіпедії, яке може відповісти на поставлене питання. У моєму випадку найближчим аналогом є такі системи, як IBM DeepQA, покладена в основу IBM Watson - програма, що може знайти відповідь на фактологічне запитання у великій базі знань і дати правильно сформульовану відповідь.

### Метрики

Для оцінювання питально-відповідальних систем використовують різні метрики. Наприклад, у SQuAD (Stanford Question Answering Dataset) є дві метрики ([Rajpurkar et al. 2016](https://arxiv.org/pdf/1606.05250.pdf)): точний збіг (відсоток відповідей, даних системою, які точно збігаються з правильними відповідями тестового сету) та макро-усереднений F1 score (відповідь від системи та правильна відповідь з сету розбиваються на токени, після чого розраховується F1 на рівні токенів для цього питання, а згодом усі F1 усереднюються для всього сету). Для фактологічних питань-відповідей, за словами Джурафскі і Мартіна ([Jurafsky, Martin 2017](https://web.stanford.edu/%7Ejurafsky/slp3/28.pdf)), часто використовують MRR - mean reciprocal rank. Оскільки такі системи зазвичай мають кілька потенційних відповідей, які система ранжує, то можна взяти обернений ранг правильної відповіді у списку потенційних відповідей (1, якщо правильна відповідь стоїть першою, 1/4 - якщо четвертою, 0 - якщо у системи нема правильної відповіді в списку) для кожного питання, і потім усереднити отримані обернені ранги для всього тестового датасету.

Для мого проекту доречно використати кожну з цих трьох метрик - точний збіг, F1, MRR.

### Бейзлайн

Дані для моєї питально-відповідальної системи досить структровані - це RDF-трійки, витягнуті з вікіпедії (хоч і не без помилок). Для отримання відповіді на питання, система, в ідеалі, зможе робити відносно простий запит у цю базу знань. Звичайно ж, формулювання питань - це неструктурований текст, який потребує обробки, щоб система "зрозуміла", якої форми запит потрібно зробити. Для бейзлайнової системи можна побудувати обробку запитань на основі правил - багато запитань мають передбачувану найбільш поширену форму, якій відповідає певна властивість ("коли народився" відповідає властивості "birthDate", наприклад). Окремі правила потрібні для знаходження еквівалентних сутностей ("США" і "Сполучені Штати", "Тарас Шевченко" і "Т.Г.Шевченко"). Така бейзлайнова система зможе "розуміти" тільки добре сформульовані запитання із досить чітко вказаним об'єктом запитання, але це має покрити велику кількість запитань, які реально ставлять люди.

### Готові рішення та State of the Art

Оскільки задача вже добре вивчена, і Watson навіть переміг у Jeopardy на телебаченні, готових рішень існує багато... для англійської мови. 

Джурафскі і Мартін описують три підходи до питально-відповідальних систем: Information Retrieval (IR) based, knowledge-based та гібридний підхід (поєднання двох попередніх). IR-підхід шукає відповіді в інтернеті або в колекції документів, що вимагає з'ясування типу відповіді (ім'я? дата? місце? тощо), формулювання запиту і знаходження частин документів, ранжованих за релевантністю для питання. Другий підхід використовує такі бази знань, як DBPedia, зі структурованими описами властивостей і зв'язків різних предметів. У цьому випадку система повинна "перекласти" питання у формі запиту для цієї бази знань (це може бути, зокрема, SPARQL-запит). Нарешті, гібридні системи використовують і поєднують обидва попередні підходи. IBM Watson належить до таких.

Система IBM DeepQA детально описана в спеціальному випуску журналу [IBM Journal of Research](http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6177717). Серед новіших статей, які використовують методи машинного та глибинного навчання і репрезентують State of the Art, є такі: 

- [Fader et al., Paraphrase-Driven Learning for Open Question Answering](http://www.aclweb.org/anthology/P13-1158);
- [Kumar et al., Ask Me Anything: Dynamic Memory Networks for Natural Language Processing](https://arxiv.org/pdf/1506.07285.pdf);
- [Hu et al., Reinforced Mnemonic Reader for Machine Comprehension](https://arxiv.org/pdf/1705.02798.pdf);
- [Chen et al., Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/pdf/1704.00051.pdf)